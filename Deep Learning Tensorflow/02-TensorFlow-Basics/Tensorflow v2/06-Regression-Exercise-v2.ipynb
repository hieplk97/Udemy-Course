{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression Exercise \n",
    "\n",
    "California Housing Data\n",
    "\n",
    "This data set contains information about all the block groups in California from the 1990 Census. In this sample a block group on average includes 1425.5 individuals living in a geographically compact area. \n",
    "\n",
    "The task is to aproximate the median house value of each block from the values of the rest of the variables. \n",
    "\n",
    " It has been obtained from the LIACC repository. The original page where the data set can be found is: http://www.liaad.up.pt/~ltorgo/Regression/DataSets.html.\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Features:\n",
    " \n",
    "* housingMedianAge: continuous. \n",
    "* totalRooms: continuous. \n",
    "* totalBedrooms: continuous. \n",
    "* population: continuous. \n",
    "* households: continuous. \n",
    "* medianIncome: continuous. \n",
    "* medianHouseValue: continuous. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Import the cal_housing_clean.csv file with pandas. Separate it into a training (70%) and testing set(30%).**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing = pd.read_csv('../data/cal_housing_clean.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>housingMedianAge</th>\n",
       "      <th>totalRooms</th>\n",
       "      <th>totalBedrooms</th>\n",
       "      <th>population</th>\n",
       "      <th>households</th>\n",
       "      <th>medianIncome</th>\n",
       "      <th>medianHouseValue</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>41.0</td>\n",
       "      <td>880.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>322.0</td>\n",
       "      <td>126.0</td>\n",
       "      <td>8.3252</td>\n",
       "      <td>452600.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>21.0</td>\n",
       "      <td>7099.0</td>\n",
       "      <td>1106.0</td>\n",
       "      <td>2401.0</td>\n",
       "      <td>1138.0</td>\n",
       "      <td>8.3014</td>\n",
       "      <td>358500.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>52.0</td>\n",
       "      <td>1467.0</td>\n",
       "      <td>190.0</td>\n",
       "      <td>496.0</td>\n",
       "      <td>177.0</td>\n",
       "      <td>7.2574</td>\n",
       "      <td>352100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>52.0</td>\n",
       "      <td>1274.0</td>\n",
       "      <td>235.0</td>\n",
       "      <td>558.0</td>\n",
       "      <td>219.0</td>\n",
       "      <td>5.6431</td>\n",
       "      <td>341300.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>52.0</td>\n",
       "      <td>1627.0</td>\n",
       "      <td>280.0</td>\n",
       "      <td>565.0</td>\n",
       "      <td>259.0</td>\n",
       "      <td>3.8462</td>\n",
       "      <td>342200.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   housingMedianAge  totalRooms  totalBedrooms  population  households  \\\n",
       "0              41.0       880.0          129.0       322.0       126.0   \n",
       "1              21.0      7099.0         1106.0      2401.0      1138.0   \n",
       "2              52.0      1467.0          190.0       496.0       177.0   \n",
       "3              52.0      1274.0          235.0       558.0       219.0   \n",
       "4              52.0      1627.0          280.0       565.0       259.0   \n",
       "\n",
       "   medianIncome  medianHouseValue  \n",
       "0        8.3252          452600.0  \n",
       "1        8.3014          358500.0  \n",
       "2        7.2574          352100.0  \n",
       "3        5.6431          341300.0  \n",
       "4        3.8462          342200.0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "housing.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>housingMedianAge</th>\n",
       "      <th>totalRooms</th>\n",
       "      <th>totalBedrooms</th>\n",
       "      <th>population</th>\n",
       "      <th>households</th>\n",
       "      <th>medianIncome</th>\n",
       "      <th>medianHouseValue</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>20640.000000</td>\n",
       "      <td>20640.000000</td>\n",
       "      <td>20640.000000</td>\n",
       "      <td>20640.000000</td>\n",
       "      <td>20640.000000</td>\n",
       "      <td>20640.000000</td>\n",
       "      <td>20640.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>28.639486</td>\n",
       "      <td>2635.763081</td>\n",
       "      <td>537.898014</td>\n",
       "      <td>1425.476744</td>\n",
       "      <td>499.539680</td>\n",
       "      <td>3.870671</td>\n",
       "      <td>206855.816909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>12.585558</td>\n",
       "      <td>2181.615252</td>\n",
       "      <td>421.247906</td>\n",
       "      <td>1132.462122</td>\n",
       "      <td>382.329753</td>\n",
       "      <td>1.899822</td>\n",
       "      <td>115395.615874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.499900</td>\n",
       "      <td>14999.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>18.000000</td>\n",
       "      <td>1447.750000</td>\n",
       "      <td>295.000000</td>\n",
       "      <td>787.000000</td>\n",
       "      <td>280.000000</td>\n",
       "      <td>2.563400</td>\n",
       "      <td>119600.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>29.000000</td>\n",
       "      <td>2127.000000</td>\n",
       "      <td>435.000000</td>\n",
       "      <td>1166.000000</td>\n",
       "      <td>409.000000</td>\n",
       "      <td>3.534800</td>\n",
       "      <td>179700.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>37.000000</td>\n",
       "      <td>3148.000000</td>\n",
       "      <td>647.000000</td>\n",
       "      <td>1725.000000</td>\n",
       "      <td>605.000000</td>\n",
       "      <td>4.743250</td>\n",
       "      <td>264725.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>52.000000</td>\n",
       "      <td>39320.000000</td>\n",
       "      <td>6445.000000</td>\n",
       "      <td>35682.000000</td>\n",
       "      <td>6082.000000</td>\n",
       "      <td>15.000100</td>\n",
       "      <td>500001.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       housingMedianAge    totalRooms  totalBedrooms    population  \\\n",
       "count      20640.000000  20640.000000   20640.000000  20640.000000   \n",
       "mean          28.639486   2635.763081     537.898014   1425.476744   \n",
       "std           12.585558   2181.615252     421.247906   1132.462122   \n",
       "min            1.000000      2.000000       1.000000      3.000000   \n",
       "25%           18.000000   1447.750000     295.000000    787.000000   \n",
       "50%           29.000000   2127.000000     435.000000   1166.000000   \n",
       "75%           37.000000   3148.000000     647.000000   1725.000000   \n",
       "max           52.000000  39320.000000    6445.000000  35682.000000   \n",
       "\n",
       "         households  medianIncome  medianHouseValue  \n",
       "count  20640.000000  20640.000000      20640.000000  \n",
       "mean     499.539680      3.870671     206855.816909  \n",
       "std      382.329753      1.899822     115395.615874  \n",
       "min        1.000000      0.499900      14999.000000  \n",
       "25%      280.000000      2.563400     119600.000000  \n",
       "50%      409.000000      3.534800     179700.000000  \n",
       "75%      605.000000      4.743250     264725.000000  \n",
       "max     6082.000000     15.000100     500001.000000  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "housing.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x_data = housing.drop(['medianHouseValue'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_val = housing['medianHouseValue']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(x_data,y_val,test_size=0.3,random_state=101)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scale the Feature Data\n",
    "\n",
    "** Use sklearn preprocessing to create a MinMaxScaler for the feature data. Fit this scaler only to the training data. Then use it to transform X_test and X_train. Then use the scaled X_test and X_train along with pd.Dataframe to re-create two dataframes of scaled data.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MinMaxScaler()"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.DataFrame(data=scaler.transform(X_train),columns = X_train.columns,index=X_train.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = pd.DataFrame(data=scaler.transform(X_test),columns = X_test.columns,index=X_test.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Feature Columns\n",
    "\n",
    "** Create the necessary tf.feature_column objects for the estimator. They should all be trated as continuous numeric_columns. **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['housingMedianAge', 'totalRooms', 'totalBedrooms', 'population',\n",
       "       'households', 'medianIncome', 'medianHouseValue'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "housing.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "age = tf.feature_column.numeric_column('housingMedianAge')\n",
    "rooms = tf.feature_column.numeric_column('totalRooms')\n",
    "bedrooms = tf.feature_column.numeric_column('totalBedrooms')\n",
    "pop = tf.feature_column.numeric_column('population')\n",
    "households = tf.feature_column.numeric_column('households')\n",
    "income = tf.feature_column.numeric_column('medianIncome')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_cols = [ age,rooms,bedrooms,pop,households,income]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Create the input function for the estimator object. (play around with batch_size and num_epochs)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\users\\administrator\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\tensorflow\\python\\util\\lazy_loader.py:63: The name tf.estimator.inputs is deprecated. Please use tf.compat.v1.estimator.inputs instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "input_func = tf.compat.v1.estimator.inputs.pandas_input_fn(x=X_train,y=y_train ,batch_size=10,num_epochs=1000,\n",
    "                                            shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Create the estimator model. Use a DNNRegressor. Play around with the hidden units! **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: C:\\Users\\ADMINI~1\\AppData\\Local\\Temp\\tmp0ggsdf7w\n",
      "INFO:tensorflow:Using config: {'_model_dir': 'C:\\\\Users\\\\ADMINI~1\\\\AppData\\\\Local\\\\Temp\\\\tmp0ggsdf7w', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': ClusterSpec({}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
     ]
    }
   ],
   "source": [
    "model = tf.estimator.DNNRegressor(hidden_units=[6,6,6],feature_columns=feat_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### ** Train the model for ~1,000 steps. (Later come back to this and train it for more and check for improvement) **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\users\\administrator\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\tensorflow\\python\\training\\training_util.py:235: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n",
      "WARNING:tensorflow:From c:\\users\\administrator\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\inputs\\queues\\feeding_queue_runner.py:60: QueueRunner.__init__ (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "WARNING:tensorflow:From c:\\users\\administrator\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\inputs\\queues\\feeding_functions.py:491: add_queue_runner (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:Layer dnn is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:From c:\\users\\administrator\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\tensorflow\\python\\keras\\optimizer_v2\\adagrad.py:82: calling Constant.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "WARNING:tensorflow:From c:\\users\\administrator\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\tensorflow\\python\\training\\monitored_session.py:906: start_queue_runners (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 0...\n",
      "INFO:tensorflow:Saving checkpoints for 0 into C:\\Users\\ADMINI~1\\AppData\\Local\\Temp\\tmp0ggsdf7w\\model.ckpt.\n",
      "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 0...\n",
      "INFO:tensorflow:loss = 51047830000.0, step = 0\n",
      "INFO:tensorflow:global_step/sec: 497.85\n",
      "INFO:tensorflow:loss = 58392064000.0, step = 100 (0.204 sec)\n",
      "INFO:tensorflow:global_step/sec: 704.702\n",
      "INFO:tensorflow:loss = 52352340000.0, step = 200 (0.144 sec)\n",
      "INFO:tensorflow:global_step/sec: 746.745\n",
      "INFO:tensorflow:loss = 41179050000.0, step = 300 (0.133 sec)\n",
      "INFO:tensorflow:global_step/sec: 741.243\n",
      "INFO:tensorflow:loss = 51197387000.0, step = 400 (0.133 sec)\n",
      "INFO:tensorflow:global_step/sec: 645.599\n",
      "INFO:tensorflow:loss = 27439933000.0, step = 500 (0.155 sec)\n",
      "INFO:tensorflow:global_step/sec: 781.783\n",
      "INFO:tensorflow:loss = 69310890000.0, step = 600 (0.131 sec)\n",
      "INFO:tensorflow:global_step/sec: 662.701\n",
      "INFO:tensorflow:loss = 33159295000.0, step = 700 (0.147 sec)\n",
      "INFO:tensorflow:global_step/sec: 658.337\n",
      "INFO:tensorflow:loss = 65234980000.0, step = 800 (0.153 sec)\n",
      "INFO:tensorflow:global_step/sec: 621.543\n",
      "INFO:tensorflow:loss = 52914754000.0, step = 900 (0.160 sec)\n",
      "INFO:tensorflow:global_step/sec: 813.562\n",
      "INFO:tensorflow:loss = 71022780000.0, step = 1000 (0.125 sec)\n",
      "INFO:tensorflow:global_step/sec: 781.78\n",
      "INFO:tensorflow:loss = 83970600000.0, step = 1100 (0.128 sec)\n",
      "INFO:tensorflow:global_step/sec: 629.358\n",
      "INFO:tensorflow:loss = 54840746000.0, step = 1200 (0.158 sec)\n",
      "INFO:tensorflow:global_step/sec: 667.121\n",
      "INFO:tensorflow:loss = 70872910000.0, step = 1300 (0.150 sec)\n",
      "INFO:tensorflow:global_step/sec: 800.545\n",
      "INFO:tensorflow:loss = 24767273000.0, step = 1400 (0.125 sec)\n",
      "INFO:tensorflow:global_step/sec: 752.389\n",
      "INFO:tensorflow:loss = 58210130000.0, step = 1500 (0.133 sec)\n",
      "INFO:tensorflow:global_step/sec: 752.391\n",
      "INFO:tensorflow:loss = 91873870000.0, step = 1600 (0.134 sec)\n",
      "INFO:tensorflow:global_step/sec: 775.723\n",
      "INFO:tensorflow:loss = 86011660000.0, step = 1700 (0.131 sec)\n",
      "INFO:tensorflow:global_step/sec: 730.421\n",
      "INFO:tensorflow:loss = 90036535000.0, step = 1800 (0.137 sec)\n",
      "INFO:tensorflow:global_step/sec: 741.245\n",
      "INFO:tensorflow:loss = 28642652000.0, step = 1900 (0.133 sec)\n",
      "INFO:tensorflow:global_step/sec: 758.089\n",
      "INFO:tensorflow:loss = 53037654000.0, step = 2000 (0.133 sec)\n",
      "INFO:tensorflow:global_step/sec: 741.243\n",
      "INFO:tensorflow:loss = 57551730000.0, step = 2100 (0.134 sec)\n",
      "INFO:tensorflow:global_step/sec: 741.249\n",
      "INFO:tensorflow:loss = 67168510000.0, step = 2200 (0.134 sec)\n",
      "INFO:tensorflow:global_step/sec: 769.75\n",
      "INFO:tensorflow:loss = 34259833000.0, step = 2300 (0.130 sec)\n",
      "INFO:tensorflow:global_step/sec: 741.92\n",
      "INFO:tensorflow:loss = 79039770000.0, step = 2400 (0.136 sec)\n",
      "INFO:tensorflow:global_step/sec: 783.069\n",
      "INFO:tensorflow:loss = 40793997000.0, step = 2500 (0.131 sec)\n",
      "INFO:tensorflow:global_step/sec: 758.089\n",
      "INFO:tensorflow:loss = 49692172000.0, step = 2600 (0.130 sec)\n",
      "INFO:tensorflow:global_step/sec: 775.723\n",
      "INFO:tensorflow:loss = 69206410000.0, step = 2700 (0.128 sec)\n",
      "INFO:tensorflow:global_step/sec: 735.792\n",
      "INFO:tensorflow:loss = 25933083000.0, step = 2800 (0.135 sec)\n",
      "WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 2817 vs previous value: 2817. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.\n",
      "INFO:tensorflow:global_step/sec: 671.598\n",
      "INFO:tensorflow:loss = 66770043000.0, step = 2900 (0.150 sec)\n",
      "INFO:tensorflow:global_step/sec: 766.321\n",
      "INFO:tensorflow:loss = 48309023000.0, step = 3000 (0.129 sec)\n",
      "INFO:tensorflow:global_step/sec: 735.795\n",
      "INFO:tensorflow:loss = 65094103000.0, step = 3100 (0.136 sec)\n",
      "INFO:tensorflow:global_step/sec: 746.768\n",
      "INFO:tensorflow:loss = 30186852000.0, step = 3200 (0.138 sec)\n",
      "INFO:tensorflow:global_step/sec: 694.923\n",
      "INFO:tensorflow:loss = 85429610000.0, step = 3300 (0.141 sec)\n",
      "INFO:tensorflow:global_step/sec: 667.115\n",
      "INFO:tensorflow:loss = 29582629000.0, step = 3400 (0.149 sec)\n",
      "INFO:tensorflow:global_step/sec: 781.79\n",
      "INFO:tensorflow:loss = 50419716000.0, step = 3500 (0.129 sec)\n",
      "WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 3578 vs previous value: 3578. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.\n",
      "INFO:tensorflow:global_step/sec: 725.124\n",
      "INFO:tensorflow:loss = 33705404000.0, step = 3600 (0.137 sec)\n",
      "INFO:tensorflow:global_step/sec: 763.88\n",
      "INFO:tensorflow:loss = 37144023000.0, step = 3700 (0.131 sec)\n",
      "INFO:tensorflow:global_step/sec: 714.776\n",
      "INFO:tensorflow:loss = 56137417000.0, step = 3800 (0.140 sec)\n",
      "WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 3862 vs previous value: 3862. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.\n",
      "INFO:tensorflow:global_step/sec: 625.417\n",
      "INFO:tensorflow:loss = 34156368000.0, step = 3900 (0.162 sec)\n",
      "INFO:tensorflow:global_step/sec: 697.247\n",
      "INFO:tensorflow:loss = 83739180000.0, step = 4000 (0.142 sec)\n",
      "INFO:tensorflow:global_step/sec: 440.826\n",
      "INFO:tensorflow:loss = 60575097000.0, step = 4100 (0.225 sec)\n",
      "INFO:tensorflow:global_step/sec: 714.776\n",
      "INFO:tensorflow:loss = 54344946000.0, step = 4200 (0.143 sec)\n",
      "INFO:tensorflow:global_step/sec: 588.636\n",
      "INFO:tensorflow:loss = 73662810000.0, step = 4300 (0.169 sec)\n",
      "INFO:tensorflow:global_step/sec: 513.167\n",
      "INFO:tensorflow:loss = 69616484000.0, step = 4400 (0.195 sec)\n",
      "INFO:tensorflow:global_step/sec: 737.812\n",
      "INFO:tensorflow:loss = 39380720000.0, step = 4500 (0.135 sec)\n",
      "INFO:tensorflow:global_step/sec: 855.279\n",
      "INFO:tensorflow:loss = 56678660000.0, step = 4600 (0.116 sec)\n",
      "INFO:tensorflow:global_step/sec: 775.716\n",
      "INFO:tensorflow:loss = 101238710000.0, step = 4700 (0.130 sec)\n",
      "INFO:tensorflow:global_step/sec: 840.914\n",
      "INFO:tensorflow:loss = 56481240000.0, step = 4800 (0.119 sec)\n",
      "INFO:tensorflow:global_step/sec: 654.038\n",
      "INFO:tensorflow:loss = 50666844000.0, step = 4900 (0.157 sec)\n",
      "INFO:tensorflow:global_step/sec: 621.54\n",
      "INFO:tensorflow:loss = 44188226000.0, step = 5000 (0.157 sec)\n",
      "INFO:tensorflow:global_step/sec: 827.01\n",
      "INFO:tensorflow:loss = 61219250000.0, step = 5100 (0.121 sec)\n",
      "INFO:tensorflow:global_step/sec: 840.904\n",
      "INFO:tensorflow:loss = 47683715000.0, step = 5200 (0.121 sec)\n",
      "INFO:tensorflow:global_step/sec: 790.458\n",
      "INFO:tensorflow:loss = 50224366000.0, step = 5300 (0.125 sec)\n",
      "INFO:tensorflow:global_step/sec: 840.914\n",
      "INFO:tensorflow:loss = 46018535000.0, step = 5400 (0.120 sec)\n",
      "INFO:tensorflow:global_step/sec: 885.552\n",
      "INFO:tensorflow:loss = 72433550000.0, step = 5500 (0.114 sec)\n",
      "INFO:tensorflow:global_step/sec: 840.911\n",
      "INFO:tensorflow:loss = 35386300000.0, step = 5600 (0.118 sec)\n",
      "INFO:tensorflow:global_step/sec: 510.549\n",
      "INFO:tensorflow:loss = 63307305000.0, step = 5700 (0.195 sec)\n",
      "INFO:tensorflow:global_step/sec: 662.703\n",
      "INFO:tensorflow:loss = 40346880000.0, step = 5800 (0.151 sec)\n",
      "INFO:tensorflow:global_step/sec: 581.789\n",
      "INFO:tensorflow:loss = 60334840000.0, step = 5900 (0.172 sec)\n",
      "INFO:tensorflow:global_step/sec: 582.661\n",
      "INFO:tensorflow:loss = 34312917000.0, step = 6000 (0.171 sec)\n",
      "INFO:tensorflow:global_step/sec: 645.598\n",
      "INFO:tensorflow:loss = 39946200000.0, step = 6100 (0.158 sec)\n",
      "INFO:tensorflow:global_step/sec: 523.916\n",
      "INFO:tensorflow:loss = 50529858000.0, step = 6200 (0.189 sec)\n",
      "INFO:tensorflow:global_step/sec: 699.777\n",
      "INFO:tensorflow:loss = 109136000000.0, step = 6300 (0.143 sec)\n",
      "INFO:tensorflow:global_step/sec: 540.907\n",
      "INFO:tensorflow:loss = 75120690000.0, step = 6400 (0.186 sec)\n",
      "INFO:tensorflow:global_step/sec: 654.952\n",
      "INFO:tensorflow:loss = 37017520000.0, step = 6500 (0.152 sec)\n",
      "INFO:tensorflow:global_step/sec: 680.731\n",
      "INFO:tensorflow:loss = 83474660000.0, step = 6600 (0.147 sec)\n",
      "INFO:tensorflow:global_step/sec: 694.918\n",
      "INFO:tensorflow:loss = 42732495000.0, step = 6700 (0.148 sec)\n",
      "INFO:tensorflow:global_step/sec: 671.595\n",
      "INFO:tensorflow:loss = 27964183000.0, step = 6800 (0.149 sec)\n",
      "INFO:tensorflow:global_step/sec: 621.546\n",
      "INFO:tensorflow:loss = 46808620000.0, step = 6900 (0.159 sec)\n",
      "INFO:tensorflow:global_step/sec: 704.705\n",
      "INFO:tensorflow:loss = 76145350000.0, step = 7000 (0.140 sec)\n",
      "INFO:tensorflow:global_step/sec: 752.391\n",
      "INFO:tensorflow:loss = 47281250000.0, step = 7100 (0.135 sec)\n",
      "INFO:tensorflow:global_step/sec: 685.394\n",
      "INFO:tensorflow:loss = 16634967000.0, step = 7200 (0.144 sec)\n",
      "INFO:tensorflow:global_step/sec: 602.82\n",
      "INFO:tensorflow:loss = 62482612000.0, step = 7300 (0.170 sec)\n",
      "INFO:tensorflow:global_step/sec: 565.355\n",
      "INFO:tensorflow:loss = 22643714000.0, step = 7400 (0.173 sec)\n",
      "INFO:tensorflow:global_step/sec: 704.705\n",
      "INFO:tensorflow:loss = 51527990000.0, step = 7500 (0.142 sec)\n",
      "INFO:tensorflow:global_step/sec: 637.375\n",
      "INFO:tensorflow:loss = 69602120000.0, step = 7600 (0.156 sec)\n",
      "INFO:tensorflow:global_step/sec: 616.61\n",
      "INFO:tensorflow:loss = 80605480000.0, step = 7700 (0.164 sec)\n",
      "INFO:tensorflow:global_step/sec: 680.733\n",
      "INFO:tensorflow:loss = 83652290000.0, step = 7800 (0.148 sec)\n",
      "INFO:tensorflow:global_step/sec: 709.69\n",
      "INFO:tensorflow:loss = 56522154000.0, step = 7900 (0.140 sec)\n",
      "INFO:tensorflow:global_step/sec: 794.206\n",
      "INFO:tensorflow:loss = 64222515000.0, step = 8000 (0.127 sec)\n",
      "INFO:tensorflow:global_step/sec: 730.424\n",
      "INFO:tensorflow:loss = 43896545000.0, step = 8100 (0.139 sec)\n",
      "INFO:tensorflow:global_step/sec: 708.546\n",
      "INFO:tensorflow:loss = 30441947000.0, step = 8200 (0.137 sec)\n",
      "WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 8273 vs previous value: 8273. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.\n",
      "INFO:tensorflow:global_step/sec: 725.141\n",
      "INFO:tensorflow:loss = 87124386000.0, step = 8300 (0.137 sec)\n",
      "INFO:tensorflow:global_step/sec: 763.873\n",
      "INFO:tensorflow:loss = 67823640000.0, step = 8400 (0.133 sec)\n",
      "INFO:tensorflow:global_step/sec: 690.126\n",
      "INFO:tensorflow:loss = 44737380000.0, step = 8500 (0.143 sec)\n",
      "INFO:tensorflow:global_step/sec: 725.131\n",
      "INFO:tensorflow:loss = 89290920000.0, step = 8600 (0.138 sec)\n",
      "INFO:tensorflow:global_step/sec: 613.912\n",
      "INFO:tensorflow:loss = 36755420000.0, step = 8700 (0.166 sec)\n",
      "INFO:tensorflow:global_step/sec: 602.817\n",
      "INFO:tensorflow:loss = 40685285000.0, step = 8800 (0.165 sec)\n",
      "INFO:tensorflow:global_step/sec: 754.711\n",
      "INFO:tensorflow:loss = 60423655000.0, step = 8900 (0.133 sec)\n",
      "INFO:tensorflow:global_step/sec: 694.922\n",
      "INFO:tensorflow:loss = 75010840000.0, step = 9000 (0.142 sec)\n",
      "INFO:tensorflow:global_step/sec: 671.596\n",
      "INFO:tensorflow:loss = 41536135000.0, step = 9100 (0.150 sec)\n",
      "INFO:tensorflow:global_step/sec: 680.734\n",
      "INFO:tensorflow:loss = 68617710000.0, step = 9200 (0.147 sec)\n",
      "INFO:tensorflow:global_step/sec: 625.422\n",
      "INFO:tensorflow:loss = 41630458000.0, step = 9300 (0.160 sec)\n",
      "INFO:tensorflow:global_step/sec: 769.761\n",
      "INFO:tensorflow:loss = 84205494000.0, step = 9400 (0.133 sec)\n",
      "INFO:tensorflow:global_step/sec: 572.324\n",
      "INFO:tensorflow:loss = 73565160000.0, step = 9500 (0.171 sec)\n",
      "INFO:tensorflow:global_step/sec: 752.393\n",
      "INFO:tensorflow:loss = 37860320000.0, step = 9600 (0.135 sec)\n",
      "INFO:tensorflow:global_step/sec: 730.427\n",
      "INFO:tensorflow:loss = 59656450000.0, step = 9700 (0.137 sec)\n",
      "INFO:tensorflow:global_step/sec: 699.754\n",
      "INFO:tensorflow:loss = 67755790000.0, step = 9800 (0.143 sec)\n",
      "INFO:tensorflow:global_step/sec: 692.202\n",
      "INFO:tensorflow:loss = 93453100000.0, step = 9900 (0.142 sec)\n",
      "INFO:tensorflow:global_step/sec: 676.129\n",
      "INFO:tensorflow:loss = 46137033000.0, step = 10000 (0.150 sec)\n",
      "INFO:tensorflow:global_step/sec: 546.823\n",
      "INFO:tensorflow:loss = 58321100000.0, step = 10100 (0.188 sec)\n",
      "INFO:tensorflow:global_step/sec: 725.132\n",
      "INFO:tensorflow:loss = 51250487000.0, step = 10200 (0.134 sec)\n",
      "INFO:tensorflow:global_step/sec: 726.925\n",
      "INFO:tensorflow:loss = 29741476000.0, step = 10300 (0.136 sec)\n",
      "INFO:tensorflow:global_step/sec: 694.921\n",
      "INFO:tensorflow:loss = 42994560000.0, step = 10400 (0.143 sec)\n",
      "INFO:tensorflow:global_step/sec: 699.777\n",
      "INFO:tensorflow:loss = 86260480000.0, step = 10500 (0.144 sec)\n",
      "INFO:tensorflow:global_step/sec: 552.859\n",
      "INFO:tensorflow:loss = 51778363000.0, step = 10600 (0.186 sec)\n",
      "INFO:tensorflow:global_step/sec: 565.358\n",
      "INFO:tensorflow:loss = 40847794000.0, step = 10700 (0.173 sec)\n",
      "INFO:tensorflow:global_step/sec: 730.398\n",
      "INFO:tensorflow:loss = 28313370000.0, step = 10800 (0.141 sec)\n",
      "INFO:tensorflow:global_step/sec: 649.808\n",
      "INFO:tensorflow:loss = 42251526000.0, step = 10900 (0.153 sec)\n",
      "INFO:tensorflow:global_step/sec: 637.378\n",
      "INFO:tensorflow:loss = 56638190000.0, step = 11000 (0.153 sec)\n",
      "INFO:tensorflow:global_step/sec: 625.423\n",
      "INFO:tensorflow:loss = 25299984000.0, step = 11100 (0.159 sec)\n",
      "INFO:tensorflow:global_step/sec: 690.127\n",
      "INFO:tensorflow:loss = 115736945000.0, step = 11200 (0.147 sec)\n",
      "INFO:tensorflow:global_step/sec: 758.089\n",
      "INFO:tensorflow:loss = 40843950000.0, step = 11300 (0.135 sec)\n",
      "INFO:tensorflow:global_step/sec: 746.888\n",
      "INFO:tensorflow:loss = 54511358000.0, step = 11400 (0.130 sec)\n",
      "INFO:tensorflow:global_step/sec: 783.926\n",
      "INFO:tensorflow:loss = 30530300000.0, step = 11500 (0.129 sec)\n",
      "INFO:tensorflow:global_step/sec: 690.124\n",
      "INFO:tensorflow:loss = 45491704000.0, step = 11600 (0.143 sec)\n",
      "INFO:tensorflow:global_step/sec: 699.776\n",
      "INFO:tensorflow:loss = 79379130000.0, step = 11700 (0.144 sec)\n",
      "INFO:tensorflow:global_step/sec: 730.422\n",
      "INFO:tensorflow:loss = 45793518000.0, step = 11800 (0.139 sec)\n",
      "INFO:tensorflow:global_step/sec: 758.094\n",
      "INFO:tensorflow:loss = 78657405000.0, step = 11900 (0.133 sec)\n",
      "INFO:tensorflow:global_step/sec: 629.354\n",
      "INFO:tensorflow:loss = 24424182000.0, step = 12000 (0.156 sec)\n",
      "INFO:tensorflow:global_step/sec: 725.135\n",
      "INFO:tensorflow:loss = 89639985000.0, step = 12100 (0.142 sec)\n",
      "INFO:tensorflow:global_step/sec: 754.601\n",
      "INFO:tensorflow:loss = 45039910000.0, step = 12200 (0.129 sec)\n",
      "INFO:tensorflow:global_step/sec: 741.243\n",
      "INFO:tensorflow:loss = 32752534000.0, step = 12300 (0.136 sec)\n",
      "INFO:tensorflow:global_step/sec: 769.751\n",
      "INFO:tensorflow:loss = 55759930000.0, step = 12400 (0.129 sec)\n",
      "WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 12473 vs previous value: 12473. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.\n",
      "INFO:tensorflow:global_step/sec: 641.459\n",
      "INFO:tensorflow:loss = 55911145000.0, step = 12500 (0.159 sec)\n",
      "INFO:tensorflow:global_step/sec: 680.738\n",
      "INFO:tensorflow:loss = 45120295000.0, step = 12600 (0.144 sec)\n",
      "INFO:tensorflow:global_step/sec: 741.243\n",
      "INFO:tensorflow:loss = 77084140000.0, step = 12700 (0.136 sec)\n",
      "INFO:tensorflow:global_step/sec: 735.795\n",
      "INFO:tensorflow:loss = 60834128000.0, step = 12800 (0.140 sec)\n",
      "INFO:tensorflow:global_step/sec: 706.528\n",
      "INFO:tensorflow:loss = 35823284000.0, step = 12900 (0.137 sec)\n",
      "INFO:tensorflow:global_step/sec: 735.792\n",
      "INFO:tensorflow:loss = 39403520000.0, step = 13000 (0.135 sec)\n",
      "INFO:tensorflow:global_step/sec: 649.792\n",
      "INFO:tensorflow:loss = 84349936000.0, step = 13100 (0.157 sec)\n",
      "INFO:tensorflow:global_step/sec: 699.775\n",
      "INFO:tensorflow:loss = 62273905000.0, step = 13200 (0.140 sec)\n",
      "INFO:tensorflow:global_step/sec: 690.123\n",
      "INFO:tensorflow:loss = 28127810000.0, step = 13300 (0.148 sec)\n",
      "INFO:tensorflow:global_step/sec: 625.427\n",
      "INFO:tensorflow:loss = 23804228000.0, step = 13400 (0.157 sec)\n",
      "INFO:tensorflow:global_step/sec: 633.34\n",
      "INFO:tensorflow:loss = 65579680000.0, step = 13500 (0.159 sec)\n",
      "INFO:tensorflow:global_step/sec: 775.726\n",
      "INFO:tensorflow:loss = 90091110000.0, step = 13600 (0.133 sec)\n",
      "INFO:tensorflow:global_step/sec: 735.166\n",
      "INFO:tensorflow:loss = 52595376000.0, step = 13700 (0.135 sec)\n",
      "INFO:tensorflow:global_step/sec: 704.708\n",
      "INFO:tensorflow:loss = 50969480000.0, step = 13800 (0.141 sec)\n",
      "INFO:tensorflow:global_step/sec: 610.731\n",
      "INFO:tensorflow:loss = 72628040000.0, step = 13900 (0.163 sec)\n",
      "INFO:tensorflow:global_step/sec: 633.342\n",
      "INFO:tensorflow:loss = 60301010000.0, step = 14000 (0.160 sec)\n",
      "INFO:tensorflow:global_step/sec: 532.275\n",
      "INFO:tensorflow:loss = 49907393000.0, step = 14100 (0.186 sec)\n",
      "INFO:tensorflow:global_step/sec: 699.777\n",
      "INFO:tensorflow:loss = 16377020000.0, step = 14200 (0.142 sec)\n",
      "INFO:tensorflow:global_step/sec: 667.12\n",
      "INFO:tensorflow:loss = 68756140000.0, step = 14300 (0.149 sec)\n",
      "INFO:tensorflow:global_step/sec: 735.795\n",
      "INFO:tensorflow:loss = 53792678000.0, step = 14400 (0.139 sec)\n",
      "INFO:tensorflow:global_step/sec: 515.813\n",
      "INFO:tensorflow:loss = 56842846000.0, step = 14500 (0.191 sec)\n",
      "INFO:tensorflow:global_step/sec: 617.703\n",
      "INFO:tensorflow:loss = 33659110000.0, step = 14600 (0.164 sec)\n",
      "INFO:tensorflow:global_step/sec: 572.977\n",
      "INFO:tensorflow:loss = 77721530000.0, step = 14700 (0.174 sec)\n",
      "INFO:tensorflow:global_step/sec: 763.88\n",
      "INFO:tensorflow:loss = 65060397000.0, step = 14800 (0.131 sec)\n",
      "INFO:tensorflow:global_step/sec: 735.791\n",
      "INFO:tensorflow:loss = 65765913000.0, step = 14900 (0.135 sec)\n",
      "INFO:tensorflow:global_step/sec: 719.894\n",
      "INFO:tensorflow:loss = 66635784000.0, step = 15000 (0.144 sec)\n",
      "INFO:tensorflow:global_step/sec: 719.931\n",
      "INFO:tensorflow:loss = 70525100000.0, step = 15100 (0.135 sec)\n",
      "INFO:tensorflow:global_step/sec: 667.114\n",
      "INFO:tensorflow:loss = 52727624000.0, step = 15200 (0.150 sec)\n",
      "INFO:tensorflow:global_step/sec: 675.26\n",
      "INFO:tensorflow:loss = 39135797000.0, step = 15300 (0.148 sec)\n",
      "INFO:tensorflow:global_step/sec: 746.779\n",
      "INFO:tensorflow:loss = 68621984000.0, step = 15400 (0.135 sec)\n",
      "INFO:tensorflow:global_step/sec: 730.425\n",
      "INFO:tensorflow:loss = 66900402000.0, step = 15500 (0.135 sec)\n",
      "INFO:tensorflow:global_step/sec: 748.06\n",
      "INFO:tensorflow:loss = 73692890000.0, step = 15600 (0.137 sec)\n",
      "INFO:tensorflow:global_step/sec: 730.422\n",
      "INFO:tensorflow:loss = 62715474000.0, step = 15700 (0.134 sec)\n",
      "INFO:tensorflow:global_step/sec: 741.242\n",
      "INFO:tensorflow:loss = 58067726000.0, step = 15800 (0.136 sec)\n",
      "INFO:tensorflow:global_step/sec: 725.131\n",
      "INFO:tensorflow:loss = 109789130000.0, step = 15900 (0.138 sec)\n",
      "INFO:tensorflow:global_step/sec: 781.783\n",
      "INFO:tensorflow:loss = 85776286000.0, step = 16000 (0.127 sec)\n",
      "INFO:tensorflow:global_step/sec: 658.342\n",
      "INFO:tensorflow:loss = 64559423000.0, step = 16100 (0.153 sec)\n",
      "INFO:tensorflow:global_step/sec: 649.793\n",
      "INFO:tensorflow:loss = 56654080000.0, step = 16200 (0.153 sec)\n",
      "INFO:tensorflow:global_step/sec: 645.596\n",
      "INFO:tensorflow:loss = 75303110000.0, step = 16300 (0.156 sec)\n",
      "INFO:tensorflow:global_step/sec: 568.57\n",
      "INFO:tensorflow:loss = 37227573000.0, step = 16400 (0.180 sec)\n",
      "INFO:tensorflow:global_step/sec: 690.124\n",
      "INFO:tensorflow:loss = 53518800000.0, step = 16500 (0.141 sec)\n",
      "INFO:tensorflow:global_step/sec: 737.494\n",
      "INFO:tensorflow:loss = 33101949000.0, step = 16600 (0.136 sec)\n",
      "INFO:tensorflow:global_step/sec: 741.241\n",
      "INFO:tensorflow:loss = 43221754000.0, step = 16700 (0.139 sec)\n",
      "INFO:tensorflow:global_step/sec: 667.124\n",
      "INFO:tensorflow:loss = 50163474000.0, step = 16800 (0.149 sec)\n",
      "INFO:tensorflow:global_step/sec: 667.113\n",
      "INFO:tensorflow:loss = 29057364000.0, step = 16900 (0.152 sec)\n",
      "INFO:tensorflow:global_step/sec: 680.741\n",
      "INFO:tensorflow:loss = 87736250000.0, step = 17000 (0.141 sec)\n",
      "INFO:tensorflow:global_step/sec: 775.719\n",
      "INFO:tensorflow:loss = 26706522000.0, step = 17100 (0.131 sec)\n",
      "INFO:tensorflow:global_step/sec: 671.506\n",
      "INFO:tensorflow:loss = 69989780000.0, step = 17200 (0.147 sec)\n",
      "INFO:tensorflow:global_step/sec: 527.737\n",
      "INFO:tensorflow:loss = 25146167000.0, step = 17300 (0.194 sec)\n",
      "INFO:tensorflow:global_step/sec: 714.777\n",
      "INFO:tensorflow:loss = 40974414000.0, step = 17400 (0.140 sec)\n",
      "INFO:tensorflow:global_step/sec: 690.126\n",
      "INFO:tensorflow:loss = 110161410000.0, step = 17500 (0.142 sec)\n",
      "INFO:tensorflow:global_step/sec: 617.696\n",
      "INFO:tensorflow:loss = 32081664000.0, step = 17600 (0.162 sec)\n",
      "INFO:tensorflow:global_step/sec: 763.891\n",
      "INFO:tensorflow:loss = 46277860000.0, step = 17700 (0.130 sec)\n",
      "INFO:tensorflow:global_step/sec: 625.425\n",
      "INFO:tensorflow:loss = 25751618000.0, step = 17800 (0.161 sec)\n",
      "INFO:tensorflow:global_step/sec: 505.391\n",
      "INFO:tensorflow:loss = 49682760000.0, step = 17900 (0.200 sec)\n",
      "INFO:tensorflow:global_step/sec: 673.537\n",
      "INFO:tensorflow:loss = 101193466000.0, step = 18000 (0.145 sec)\n",
      "INFO:tensorflow:global_step/sec: 588.63\n",
      "INFO:tensorflow:loss = 57780142000.0, step = 18100 (0.172 sec)\n",
      "INFO:tensorflow:global_step/sec: 633.344\n",
      "INFO:tensorflow:loss = 45117270000.0, step = 18200 (0.157 sec)\n",
      "INFO:tensorflow:global_step/sec: 518.49\n",
      "INFO:tensorflow:loss = 35905528000.0, step = 18300 (0.195 sec)\n",
      "INFO:tensorflow:global_step/sec: 492.942\n",
      "INFO:tensorflow:loss = 63686386000.0, step = 18400 (0.204 sec)\n",
      "INFO:tensorflow:global_step/sec: 552.866\n",
      "INFO:tensorflow:loss = 73981150000.0, step = 18500 (0.182 sec)\n",
      "INFO:tensorflow:global_step/sec: 595.63\n",
      "INFO:tensorflow:loss = 41181710000.0, step = 18600 (0.167 sec)\n",
      "INFO:tensorflow:global_step/sec: 568.577\n",
      "INFO:tensorflow:loss = 49074890000.0, step = 18700 (0.174 sec)\n",
      "INFO:tensorflow:global_step/sec: 585.192\n",
      "INFO:tensorflow:loss = 48570020000.0, step = 18800 (0.171 sec)\n",
      "INFO:tensorflow:global_step/sec: 606.475\n",
      "INFO:tensorflow:loss = 44287922000.0, step = 18900 (0.166 sec)\n",
      "INFO:tensorflow:global_step/sec: 714.77\n",
      "INFO:tensorflow:loss = 50678850000.0, step = 19000 (0.139 sec)\n",
      "INFO:tensorflow:global_step/sec: 606.451\n",
      "INFO:tensorflow:loss = 53106760000.0, step = 19100 (0.166 sec)\n",
      "INFO:tensorflow:global_step/sec: 622.027\n",
      "INFO:tensorflow:loss = 30193654000.0, step = 19200 (0.161 sec)\n",
      "INFO:tensorflow:global_step/sec: 508.92\n",
      "INFO:tensorflow:loss = 85087300000.0, step = 19300 (0.195 sec)\n",
      "INFO:tensorflow:global_step/sec: 636.385\n",
      "INFO:tensorflow:loss = 53100470000.0, step = 19400 (0.159 sec)\n",
      "INFO:tensorflow:global_step/sec: 667.111\n",
      "INFO:tensorflow:loss = 32460620000.0, step = 19500 (0.148 sec)\n",
      "INFO:tensorflow:global_step/sec: 532.892\n",
      "INFO:tensorflow:loss = 55506590000.0, step = 19600 (0.187 sec)\n",
      "INFO:tensorflow:global_step/sec: 546.82\n",
      "INFO:tensorflow:loss = 32550918000.0, step = 19700 (0.187 sec)\n",
      "INFO:tensorflow:global_step/sec: 526.676\n",
      "INFO:tensorflow:loss = 71082940000.0, step = 19800 (0.185 sec)\n",
      "INFO:tensorflow:global_step/sec: 546.82\n",
      "INFO:tensorflow:loss = 63304565000.0, step = 19900 (0.186 sec)\n",
      "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 20000...\n",
      "INFO:tensorflow:Saving checkpoints for 20000 into C:\\Users\\ADMINI~1\\AppData\\Local\\Temp\\tmp0ggsdf7w\\model.ckpt.\n",
      "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 20000...\n",
      "INFO:tensorflow:Loss for final step: 44837646000.0.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow_estimator.python.estimator.canned.dnn.DNNRegressorV2 at 0x163866fe940>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.train(input_fn=input_func,steps=20000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Create a prediction input function and then use the .predict method off your estimator model to create a list or predictions on your test data. **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_input_func = tf.compat.v1.estimator.inputs.pandas_input_fn(x=X_test, batch_size=10, num_epochs=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_gen = model.predict(predict_input_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:Layer dnn is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\ADMINI~1\\AppData\\Local\\Temp\\tmp0ggsdf7w\\model.ckpt-20000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    }
   ],
   "source": [
    "predictions = list(pred_gen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Calculate the RMSE. You should be able to get around 100,000 RMSE (remember that this is in the same units as the label.) Do this manually or use [sklearn.metrics](http://scikit-learn.org/stable/modules/generated/sklearn.metrics.mean_squared_error.html) **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_preds = []\n",
    "for pred in predictions:\n",
    "    final_preds.append(pred['predictions'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "238010.32646612704"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_test,final_preds)**0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Great Job!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
